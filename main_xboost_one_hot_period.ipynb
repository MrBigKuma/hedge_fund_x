{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hedge Fund X\n",
    "This notebook solve the Hedge Fund X's competition challenge: Financial Modeling challenge.\n",
    "This one is used to evaluate model, tuning param to find most sutable model.\n",
    "To discover data set, check the other Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library & Initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T00:16:18.705265Z",
     "start_time": "2017-11-24T00:16:17.020007Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T00:16:33.489359Z",
     "start_time": "2017-11-24T00:16:18.706871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>period</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>...</th>\n",
       "      <th>c80</th>\n",
       "      <th>c81</th>\n",
       "      <th>c82</th>\n",
       "      <th>c83</th>\n",
       "      <th>c84</th>\n",
       "      <th>c85</th>\n",
       "      <th>c86</th>\n",
       "      <th>c87</th>\n",
       "      <th>c88</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>train1</td>\n",
       "      <td>0.655570</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000539</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023358</td>\n",
       "      <td>-0.017041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.140220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>train1</td>\n",
       "      <td>1.646430</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.008367</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059429</td>\n",
       "      <td>-0.009109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004382</td>\n",
       "      <td>0.455767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>train1</td>\n",
       "      <td>-0.743010</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>-0.003290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219566</td>\n",
       "      <td>0.072711</td>\n",
       "      <td>1.155580</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>train1</td>\n",
       "      <td>0.029770</td>\n",
       "      <td>-0.006343</td>\n",
       "      <td>-0.000635</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005501</td>\n",
       "      <td>0.045308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.148852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.101181</td>\n",
       "      <td>-0.954553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>train1</td>\n",
       "      <td>-0.660243</td>\n",
       "      <td>0.012591</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>-0.022264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029034</td>\n",
       "      <td>-0.005847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004842</td>\n",
       "      <td>0.436002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id  period        c1        c2        c3        c4   c5   c6  \\\n",
       "0        2  train1  0.655570 -0.000022 -0.000539 -0.001075  0.0  0.0   \n",
       "1        3  train1  1.646430 -0.000292 -0.008367  0.009497  0.0  0.0   \n",
       "2        5  train1 -0.743010  0.004642 -0.000647 -0.003290  0.0  0.0   \n",
       "3        7  train1  0.029770 -0.006343 -0.000635 -0.002516  0.0  0.0   \n",
       "4       10  train1 -0.660243  0.012591 -0.002098 -0.022264  0.0  0.0   \n",
       "\n",
       "         c7   c8   ...         c80       c81  c82       c83  c84  c85  \\\n",
       "0  0.213390  0.0   ...   -0.023358 -0.017041  0.0  0.060697  0.0  0.0   \n",
       "1  0.000000  0.0   ...   -0.059429 -0.009109  0.0  0.021645  0.0  0.0   \n",
       "2  0.000000  0.0   ...    0.001796 -0.000104  0.0 -0.024718  0.0  0.0   \n",
       "3  0.160313  0.0   ...   -0.005501  0.045308  0.0 -0.148852  0.0  0.0   \n",
       "4  0.000000  0.0   ...    0.029034 -0.005847  0.0 -0.007073  0.0  0.0   \n",
       "\n",
       "        c86       c87       c88  target  \n",
       "0  0.000000 -0.000202 -0.140220       1  \n",
       "1  0.000000 -0.004382  0.455767       0  \n",
       "2  0.219566  0.072711  1.155580       0  \n",
       "3  0.000000 -0.101181 -0.954553       0  \n",
       "4  0.000000 -0.004842  0.436002       0  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/hedge_fund_x/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/hedge_fund_x/test.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutating util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T00:16:33.493779Z",
     "start_time": "2017-11-24T00:16:33.490907Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_val_score(scores, label):\n",
    "    print \"{}: {:.2f} (+/- {:.2f})\".format(\n",
    "        label,\n",
    "        scores[label].mean(), \n",
    "        scores[label].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluate period prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### With all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T12:26:04.021501Z",
     "start_time": "2017-11-21T12:26:04.007690Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_val_score(scores, label):\n",
    "    print \"{}: {:.2f} (+/- {:.2f})\".format(label, scores[label].mean(),\n",
    "                                           scores[label].std())\n",
    "\n",
    "\n",
    "def evaluate(est, train_df, excluded_cols=['period', 'target']):\n",
    "    selected_cols = [\n",
    "        col for col in train_df.columns if col not in excluded_cols\n",
    "    ]\n",
    "    X_train = train_df[selected_cols].values\n",
    "    y_train = train_df['period'].values\n",
    "    scoring = {'acc': 'accuracy', 'log_loss': 'neg_log_loss'}\n",
    "    scores = cross_validate(\n",
    "        estimator=est,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        cv=10,\n",
    "        scoring=scoring,\n",
    "        verbose=True)\n",
    "    print_val_score(scores, 'train_acc')\n",
    "    print_val_score(scores, 'test_acc')\n",
    "    print_val_score(scores, 'train_log_loss')\n",
    "    print_val_score(scores, 'test_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T12:19:53.158803Z",
     "start_time": "2017-11-21T12:19:53.156025Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf_xgb_period = XGBClassifier(\n",
    "    max_depth=7,\n",
    "    n_estimators=150,\n",
    "    reg_lambda=100,\n",
    "    objective='multi:softmax',\n",
    "    nthread=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T12:19:54.438730Z",
     "start_time": "2017-11-21T12:19:54.424548Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 91)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([df[x * 40000:x * 40000 + 1000] for x in range(0, 14)])\n",
    "print train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-21T12:42:43.357682Z",
     "start_time": "2017-11-21T12:28:07.472731Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.97 (+/- 0.00)\n",
      "test_acc: 0.86 (+/- 0.01)\n",
      "train_log_loss: -0.29 (+/- 0.00)\n",
      "test_log_loss: -0.62 (+/- 0.02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 14.6min finished\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_acc'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('train_log_loss'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "excluded_cols = ['data_id', 'period', 'target']\n",
    "evaluate(clf_xgb_period, train_df, excluded_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate_period(est, train_df, excluded_cols=['period', 'target']):\n",
    "    selected_cols = [\n",
    "        col for col in train_df.columns if col not in excluded_cols\n",
    "    ]\n",
    "    X_test = train_df[selected_cols].values\n",
    "    y_test = train_df['target'].values\n",
    "    y_pred = est.predict(X_test)\n",
    "    y_pred_proba = clf_xgb.predict_proba(X_test)[:, 1]\n",
    "    return y_pred, y_pred_proba, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate target prediction with 1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T00:16:33.984391Z",
     "start_time": "2017-11-24T00:16:33.495327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7 7 7 7]\n",
      "[[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "oh = OneHotEncoder()\n",
    "le = LabelEncoder()\n",
    "period_values = df['period']\n",
    "le_period = le.fit_transform(period_values)\n",
    "print le_period[90000:90005]\n",
    "oh_period = oh.fit_transform(le_period.reshape(-1,1)).toarray()\n",
    "print oh_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T00:16:34.151959Z",
     "start_time": "2017-11-24T00:16:33.985969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data_id  period        c1        c2        c3        c4   c5   c6  \\\n",
      "0        2  train1  0.655570 -0.000022 -0.000539 -0.001075  0.0  0.0   \n",
      "1        3  train1  1.646430 -0.000292 -0.008367  0.009497  0.0  0.0   \n",
      "2        5  train1 -0.743010  0.004642 -0.000647 -0.003290  0.0  0.0   \n",
      "3        7  train1  0.029770 -0.006343 -0.000635 -0.002516  0.0  0.0   \n",
      "4       10  train1 -0.660243  0.012591 -0.002098 -0.022264  0.0  0.0   \n",
      "\n",
      "         c7   c8 ...     4    5    6    7    8    9   10   11   12   13  \n",
      "0  0.213390  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.000000  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.000000  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3  0.160313  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4  0.000000  0.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 105 columns]\n"
     ]
    }
   ],
   "source": [
    "oh_period_df = pd.DataFrame(oh_period)\n",
    "enc_df = pd.concat([df, oh_period_df], axis=1)\n",
    "print enc_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Period prediction with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T00:16:45.553087Z",
     "start_time": "2017-11-24T00:16:45.546538Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_target_prediction(est, train_df, excluded_cols = ['period', 'target']):\n",
    "    selected_cols = [col for col in train_df.columns if col not in excluded_cols]\n",
    "    X_train = train_df[selected_cols].values\n",
    "    y_train = train_df['target'].values\n",
    "\n",
    "    scoring={'acc':'accuracy', 'log_loss':'neg_log_loss'}\n",
    "    scores = cross_validate(estimator=est, X=X_train, y=y_train, cv=10, scoring=scoring, \n",
    "                            return_train_score=True)\n",
    "    print_val_score(scores, 'train_acc')\n",
    "    print_val_score(scores, 'test_acc')\n",
    "    print_val_score(scores, 'train_log_loss')\n",
    "    print_val_score(scores, 'test_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T00:16:47.711241Z",
     "start_time": "2017-11-24T00:16:47.311068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560000, 105)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([enc_df[x*40000: x*40000 + 40000] for x in range(0,14)])\n",
    "print train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-24T00:16:48.359254Z",
     "start_time": "2017-11-24T00:16:48.355262Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_xgb = XGBClassifier(max_depth=7, n_estimators=150, reg_lambda=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-24T00:16:51.450Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excluded_cols = ['data_id', 'period', 'target']\n",
    "evaluate_target_prediction(clf_xgb, train_df, excluded_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate target prediction with 14 different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Train 14 target models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T05:02:03.976387Z",
     "start_time": "2017-11-22T05:02:03.783167Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560000, 91)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([df[x * 40000:x * 40000 + 40000] for x in range(0, 14)])\n",
    "print train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T05:02:04.766343Z",
     "start_time": "2017-11-22T05:02:04.091699Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train1' 'train2' 'train3' 'train4' 'train5' 'train6' 'train7' 'train8'\n",
      " 'train9' 'train10' 'train11' 'train12' 'train13' 'train14']\n",
      "       data_id  period        c1        c2        c3        c4        c5  \\\n",
      "40000   104722  train2 -1.451848 -0.013567 -0.004916 -0.009638  0.000000   \n",
      "40001   104726  train2  0.056674  0.009975 -0.000008 -0.000356  0.000000   \n",
      "40002   104728  train2  1.178704 -0.002399 -0.063818  0.060751  0.000000   \n",
      "40003   104733  train2 -1.654064 -0.015497  0.004427 -0.014378  0.000000   \n",
      "40004   104734  train2  0.347447  0.020259  0.013636  0.000040  0.297327   \n",
      "\n",
      "           c6   c7   c8   ...         c80       c81  c82       c83  c84  c85  \\\n",
      "40000  0.0000  0.0  0.0   ...   -0.056786  0.018370  0.0  0.000176  0.0  0.0   \n",
      "40001  0.0000  0.0  0.0   ...   -0.048978  0.084390  0.0 -0.044561  0.0  0.0   \n",
      "40002  0.4453  0.0  0.0   ...   -0.133619  0.011723  0.0 -0.027450  0.0  0.0   \n",
      "40003  0.0000  0.0  0.0   ...   -0.196004  0.037729  0.0 -0.006746  0.0  0.0   \n",
      "40004  0.0000  0.0  0.0   ...    0.166259 -0.183191  0.0  0.122620  0.0  0.0   \n",
      "\n",
      "       c86       c87       c88  target  \n",
      "40000  0.0  0.001179  1.952686       0  \n",
      "40001  0.0 -0.009645  0.245237       0  \n",
      "40002  0.0 -0.007531  1.041051       0  \n",
      "40003  0.0 -0.001479  1.679962       0  \n",
      "40004  0.0  0.057559  1.572467       0  \n",
      "\n",
      "[5 rows x 91 columns]\n"
     ]
    }
   ],
   "source": [
    "periods = train_df['period'].unique()\n",
    "print periods\n",
    "X_periods = [train_df[train_df['period'] == p ] for p in periods]\n",
    "print X_periods[1].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T05:25:29.065219Z",
     "start_time": "2017-11-22T05:04:57.408789Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate for period train1\n",
      "train_acc: 0.80 (+/- 0.00)\n",
      "test_acc: 0.76 (+/- 0.01)\n",
      "train_log_loss: -0.55 (+/- 0.00)\n",
      "test_log_loss: -0.57 (+/- 0.00)\n",
      "Evaluate for period train2\n",
      "train_acc: 0.78 (+/- 0.00)\n",
      "test_acc: 0.73 (+/- 0.01)\n",
      "train_log_loss: -0.56 (+/- 0.00)\n",
      "test_log_loss: -0.59 (+/- 0.00)\n",
      "Evaluate for period train3\n",
      "train_acc: 0.79 (+/- 0.00)\n",
      "test_acc: 0.75 (+/- 0.01)\n",
      "train_log_loss: -0.54 (+/- 0.00)\n",
      "test_log_loss: -0.56 (+/- 0.00)\n",
      "Evaluate for period train4\n",
      "train_acc: 0.80 (+/- 0.00)\n",
      "test_acc: 0.76 (+/- 0.01)\n",
      "train_log_loss: -0.53 (+/- 0.00)\n",
      "test_log_loss: -0.56 (+/- 0.00)\n",
      "Evaluate for period train5\n",
      "train_acc: 0.76 (+/- 0.00)\n",
      "test_acc: 0.73 (+/- 0.01)\n",
      "train_log_loss: -0.54 (+/- 0.00)\n",
      "test_log_loss: -0.57 (+/- 0.00)\n",
      "Evaluate for period train6\n",
      "train_acc: 0.79 (+/- 0.00)\n",
      "test_acc: 0.75 (+/- 0.01)\n",
      "train_log_loss: -0.54 (+/- 0.00)\n",
      "test_log_loss: -0.56 (+/- 0.00)\n",
      "Evaluate for period train7\n",
      "train_acc: 0.79 (+/- 0.00)\n",
      "test_acc: 0.75 (+/- 0.01)\n",
      "train_log_loss: -0.53 (+/- 0.00)\n",
      "test_log_loss: -0.56 (+/- 0.00)\n",
      "Evaluate for period train8\n",
      "train_acc: 0.79 (+/- 0.00)\n",
      "test_acc: 0.75 (+/- 0.01)\n",
      "train_log_loss: -0.54 (+/- 0.00)\n",
      "test_log_loss: -0.57 (+/- 0.00)\n",
      "Evaluate for period train9\n",
      "train_acc: 0.79 (+/- 0.00)\n",
      "test_acc: 0.75 (+/- 0.01)\n",
      "train_log_loss: -0.56 (+/- 0.00)\n",
      "test_log_loss: -0.58 (+/- 0.00)\n",
      "Evaluate for period train10\n",
      "train_acc: 0.79 (+/- 0.00)\n",
      "test_acc: 0.75 (+/- 0.01)\n",
      "train_log_loss: -0.53 (+/- 0.00)\n",
      "test_log_loss: -0.55 (+/- 0.00)\n",
      "Evaluate for period train11\n",
      "train_acc: 0.79 (+/- 0.00)\n",
      "test_acc: 0.75 (+/- 0.01)\n",
      "train_log_loss: -0.54 (+/- 0.00)\n",
      "test_log_loss: -0.57 (+/- 0.00)\n",
      "Evaluate for period train12\n",
      "train_acc: 0.80 (+/- 0.00)\n",
      "test_acc: 0.76 (+/- 0.01)\n",
      "train_log_loss: -0.52 (+/- 0.00)\n",
      "test_log_loss: -0.55 (+/- 0.00)\n",
      "Evaluate for period train13\n",
      "train_acc: 0.78 (+/- 0.00)\n",
      "test_acc: 0.74 (+/- 0.01)\n",
      "train_log_loss: -0.55 (+/- 0.00)\n",
      "test_log_loss: -0.57 (+/- 0.00)\n",
      "Evaluate for period train14\n",
      "train_acc: 0.80 (+/- 0.00)\n",
      "test_acc: 0.76 (+/- 0.01)\n",
      "train_log_loss: -0.51 (+/- 0.00)\n",
      "test_log_loss: -0.54 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_target_prediction(est,\n",
    "                               train_df,\n",
    "                               excluded_cols=['period', 'target']):\n",
    "    selected_cols = [\n",
    "        col for col in train_df.columns if col not in excluded_cols\n",
    "    ]\n",
    "    X_train = train_df[selected_cols].values\n",
    "    y_train = train_df['target'].values\n",
    "\n",
    "    scoring = {'acc': 'accuracy', 'log_loss': 'neg_log_loss'}\n",
    "    scores = cross_validate(\n",
    "        estimator=est,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        cv=10,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True)\n",
    "    print_val_score(scores, 'train_acc')\n",
    "    print_val_score(scores, 'test_acc')\n",
    "    print_val_score(scores, 'train_log_loss')\n",
    "    print_val_score(scores, 'test_log_loss')\n",
    "\n",
    "\n",
    "excluded_cols = ['data_id', 'period', 'target']\n",
    "clf_xgb_1of14 = XGBClassifier(\n",
    "    max_depth=5, n_estimators=100, reg_lambda=100, min_child_weight=1,nthread=10\n",
    ")\n",
    "# TODO: test on 3 first period\n",
    "for i, X in enumerate(X_periods[:]):\n",
    "    print \"Evaluate for period {}\".format(periods[i])\n",
    "    evaluate_target_prediction(clf_xgb_1of14, X, excluded_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost classifier 14 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T11:34:22.243237Z",
     "start_time": "2017-11-23T11:34:22.133032Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Xgb14Classifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    The input for the classifier is dataframe to let us detect period\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, excluded_cols=[], verbose=False):\n",
    "        self._estimator_type = 'classifier'\n",
    "        self.verbose = verbose\n",
    "        self.excluded_cols = excluded_cols\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.selected_cols = [\n",
    "            col for col in X.columns\n",
    "            if col not in (\n",
    "                self.excluded_cols + ['data_id', 'period', 'target'])\n",
    "        ]\n",
    "        # y is required for cross validation purpose\n",
    "        periods = X['period'].unique()\n",
    "        X_periods = {p: X[X['period'] == p] for p in periods}\n",
    "        self.clf_xgb_list = {}\n",
    "        # Train 14 models\n",
    "        for period in periods:\n",
    "            X_period = X_periods[period]\n",
    "            if self.verbose:\n",
    "                print \"Train period {} with {} data\".format(\n",
    "                    period, X_period.shape[0])\n",
    "            X_train = X_period[self.selected_cols].values\n",
    "            y_train = X_period['target'].values\n",
    "            clf_xgb = XGBClassifier(\n",
    "                max_depth=5,\n",
    "                n_estimators=100,\n",
    "                reg_lambda=100,\n",
    "                min_child_weight=1,\n",
    "                nthread=10)\n",
    "            clf_xgb.fit(X_train, y_train)\n",
    "            self.clf_xgb_list[period] = clf_xgb\n",
    "\n",
    "            # Train period prediction\n",
    "            #         if self.verbose: print \"Train clf_xgb_period\"\n",
    "            #         clf_xgb_period = XGBClassifier(\n",
    "            #             max_depth=7,\n",
    "            #             n_estimators=150,\n",
    "            #             reg_lambda=100,\n",
    "            #             objective='multi:softmax',\n",
    "            #             nthread=10)\n",
    "            #         X_period_train = X[self.selected_cols].values\n",
    "            #         y_period_train = X['period'].values\n",
    "            #         clf_xgb_period.fit(X_period_train, y_period_train)\n",
    "            #         self.clf_xgb_period = clf_xgb_period\n",
    "            self.clf_xgb_period = joblib.load(\n",
    "                'clf_xgb14_period_40000_all_param.pkl')\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict_transform_period(self, X):\n",
    "        if self.verbose: print \"Predict period\"\n",
    "        try:\n",
    "            getattr(self, \"clf_xgb_period\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"Transformer hasn't been trained yet\")\n",
    "        X_train = X[self.selected_cols].values\n",
    "        X_period = self.clf_xgb_period.predict(X_train)\n",
    "        X_period_df = pd.DataFrame(X_period, columns=['period'])\n",
    "        X_drop = X.reset_index(drop=True)\n",
    "        if 'period' in X_drop.columns:\n",
    "            X_drop = X_drop.drop('period', axis=1)\n",
    "        return pd.concat([X_drop, X_period_df], axis=1)\n",
    "\n",
    "    def predict_proba(self, X, y=None):\n",
    "        if len(self.clf_xgb_list) == 0:\n",
    "            print X['period'].unique()\n",
    "            raise RuntimeError(\"No classifier is trained\")\n",
    "        X = self._predict_transform_period(X)\n",
    "        periods = X['period'].unique()\n",
    "        if (len(periods) > len(self.clf_xgb_list)):\n",
    "            raise RuntimeError(\n",
    "                \"Test data has more period then trained classifiers\")\n",
    "        data_id_map = {\n",
    "            data_id: idx\n",
    "            for idx, data_id in enumerate(X['data_id'].values)\n",
    "        }\n",
    "        X_periods = {p: X[X['period'] == p] for p in periods}\n",
    "        rst = np.empty((len(data_id_map), 2))\n",
    "        for p in periods:\n",
    "            if self.verbose: print \"Predict period {}\".format(p)\n",
    "            X_period = X_periods[p]\n",
    "            clf = self.clf_xgb_list[p]\n",
    "            X_test = X_period[self.selected_cols].values\n",
    "            pred = clf.predict_proba(X_test)\n",
    "            for idx, data_id in enumerate(X_period['data_id']):\n",
    "                rst[data_id_map[data_id]] = pred[idx]\n",
    "\n",
    "        return rst\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        if len(self.clf_xgb_list) == 0:\n",
    "            raise RuntimeError(\"No classifier is trained\")\n",
    "        X = self._predict_transform_period(X)\n",
    "        periods = X['period'].unique()\n",
    "        if (len(periods) > len(self.clf_xgb_list)):\n",
    "            print X['period'].unique()\n",
    "            raise RuntimeError(\n",
    "                \"Test data has more period then trained classifiers\")\n",
    "        data_id_map = {\n",
    "            data_id: idx\n",
    "            for idx, data_id in enumerate(X['data_id'].values)\n",
    "        }\n",
    "        X_periods = {p: X[X['period'] == p] for p in periods}\n",
    "        rst = np.empty(len(data_id_map))\n",
    "        for p in periods:\n",
    "            if self.verbose: print \"Predict period {}\".format(p)\n",
    "            X_period = X_periods[p]\n",
    "            clf = self.clf_xgb_list[p]\n",
    "            X_test = X_period[self.selected_cols].values\n",
    "            pred = clf.predict(X_test)\n",
    "            for idx, data_id in enumerate(X_period['data_id']):\n",
    "                rst[data_id_map[data_id]] = pred[idx]\n",
    "\n",
    "        return rst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the custom classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T09:46:13.412706Z",
     "start_time": "2017-11-23T09:46:13.399338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 91)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([df[x * 40000:x * 40000 + 100]\n",
    "                      for x in range(0, 14)]).reset_index(drop=True)\n",
    "print train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T09:49:55.879518Z",
     "start_time": "2017-11-23T09:48:21.071291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xgb14Classifier(excluded_cols=[], verbose=False)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb_14 = Xgb14Classifier()\n",
    "clf_xgb_14.fit(train_df, train_df['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T09:46:25.177968Z",
     "start_time": "2017-11-23T09:46:25.160887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 91)\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.concat([df[x * 40000 + 1000:x * 40000 + 2000] \n",
    "                    for x in range(0, 14)]).reset_index(drop=True)\n",
    "print val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T09:46:26.160934Z",
     "start_time": "2017-11-23T09:46:25.180183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 2)\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_xgb_14.predict_proba(val_df)\n",
    "print y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation the custom classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T12:52:45.145999Z",
     "start_time": "2017-11-23T12:52:44.860675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560000, 91)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([df[x * 40000:x * 40000 + 40000]\n",
    "                      for x in range(0, 14)]).reset_index(drop=True)\n",
    "print train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-23T13:49:02.826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period train13 with 27918 data\n",
      "Train period train6 with 28036 data\n",
      "Train period train1 with 27966 data\n",
      "Train period train2 with 28014 data\n",
      "Train period train12 with 27960 data\n",
      "Train period train11 with 28035 data\n",
      "Train period train10 with 27859 data\n",
      "Train period train4 with 27885 data\n",
      "Train period train9 with 28054 data\n",
      "Train period train8 with 28090 data\n",
      "Train period train5 with 28035 data\n",
      "Train period train3 with 28062 data\n",
      "Train period train14 with 27970 data\n",
      "Train period train7 with 28116 data\n",
      "Predict period\n",
      "Predict period train9\n",
      "Predict period train10\n",
      "Predict period train2\n",
      "Predict period train5\n",
      "Predict period train12\n",
      "Predict period train11\n",
      "Predict period train6\n",
      "Predict period train4\n",
      "Predict period train8\n",
      "Predict period train1\n",
      "Predict period train14\n",
      "Predict period train13\n",
      "Predict period train7\n",
      "Predict period train3\n",
      "Predict period\n",
      "Predict period train9\n",
      "Predict period train10\n",
      "Predict period train2\n",
      "Predict period train5\n",
      "Predict period train12\n",
      "Predict period train11\n",
      "Predict period train6\n",
      "Predict period train4\n",
      "Predict period train8\n",
      "Predict period train1\n",
      "Predict period train14\n",
      "Predict period train13\n",
      "Predict period train7\n",
      "Predict period train3\n",
      "Predict period\n",
      "Predict period train13\n",
      "Predict period train6\n",
      "Predict period train1\n",
      "Predict period train2\n",
      "Predict period train12\n",
      "Predict period train11\n",
      "Predict period train10\n",
      "Predict period train4\n",
      "Predict period train8\n",
      "Predict period train5\n",
      "Predict period train3\n",
      "Predict period train14\n",
      "Predict period train7\n",
      "Predict period train9\n",
      "Predict period\n",
      "Predict period train13\n",
      "Predict period train6\n",
      "Predict period train1\n",
      "Predict period train2\n",
      "Predict period train12\n",
      "Predict period train11\n",
      "Predict period train10\n",
      "Predict period train4\n",
      "Predict period train8\n",
      "Predict period train5\n",
      "Predict period train3\n",
      "Predict period train14\n",
      "Predict period train7\n",
      "Predict period train9\n",
      "Train period train10 with 27902 data\n",
      "Train period train1 with 27903 data\n",
      "Train period train8 with 28027 data\n",
      "Train period train11 with 27956 data\n",
      "Train period train7 with 28046 data\n",
      "Train period train9 with 28021 data\n",
      "Train period train2 with 28014 data\n",
      "Train period train13 with 27861 data\n",
      "Train period train6 with 27857 data\n",
      "Train period train14 with 28150 data\n",
      "Train period train5 with 28071 data\n",
      "Train period train4 with 28147 data\n",
      "Train period train12 with 27978 data\n",
      "Train period train3 with 28067 data\n",
      "Predict period\n",
      "Predict period train7\n",
      "Predict period train9\n",
      "Predict period train3\n",
      "Predict period train4\n",
      "Predict period train11\n",
      "Predict period train2\n",
      "Predict period train13\n",
      "Predict period train12\n",
      "Predict period train1\n",
      "Predict period train8\n",
      "Predict period train5\n",
      "Predict period train14\n",
      "Predict period train6\n",
      "Predict period train10\n",
      "Predict period\n",
      "Predict period train7\n",
      "Predict period train9\n",
      "Predict period train3\n",
      "Predict period train4\n",
      "Predict period train11\n",
      "Predict period train2\n",
      "Predict period train13\n",
      "Predict period train12\n",
      "Predict period train1\n",
      "Predict period train8\n",
      "Predict period train5\n",
      "Predict period train14\n",
      "Predict period train6\n",
      "Predict period train10\n",
      "Predict period\n",
      "Predict period train10\n",
      "Predict period train1\n",
      "Predict period train12\n",
      "Predict period train11\n",
      "Predict period train7\n",
      "Predict period train9\n",
      "Predict period train2\n",
      "Predict period train13\n",
      "Predict period train6\n",
      "Predict period train14\n",
      "Predict period train8\n",
      "Predict period train5\n",
      "Predict period train4\n",
      "Predict period train3\n",
      "Predict period\n",
      "Predict period train10\n",
      "Predict period train1\n",
      "Predict period train12\n",
      "Predict period train11\n",
      "Predict period train7\n",
      "Predict period train9\n",
      "Predict period train2\n",
      "Predict period train13\n",
      "Predict period train6\n",
      "Predict period train14\n",
      "Predict period train8\n",
      "Predict period train5\n",
      "Predict period train4\n",
      "Predict period train3\n",
      "Train period train13 with 27944 data\n",
      "Train period train10 with 28043 data\n",
      "Train period train3 with 27797 data\n",
      "Train period train4 with 27830 data\n",
      "Train period train9 with 27969 data\n",
      "Train period train8 with 28144 data\n",
      "Train period train7 with 28071 data\n",
      "Train period train2 with 28173 data\n",
      "Train period train6 with 28034 data\n",
      "Train period train11 with 28087 data\n",
      "Train period train12 with 28032 data\n",
      "Train period train5 with 27949 data\n",
      "Train period train14 with 27958 data\n",
      "Train period train1 with 27969 data\n",
      "Predict period\n",
      "Predict period train13\n",
      "Predict period train5\n",
      "Predict period train10\n",
      "Predict period train8\n",
      "Predict period train4\n",
      "Predict period train3\n",
      "Predict period train12\n",
      "Predict period train6\n",
      "Predict period train9\n",
      "Predict period train7\n",
      "Predict period train14\n",
      "Predict period train2\n",
      "Predict period train11\n",
      "Predict period train1\n",
      "Predict period\n",
      "Predict period train13\n",
      "Predict period train5\n",
      "Predict period train10\n",
      "Predict period train8\n",
      "Predict period train4\n",
      "Predict period train3\n",
      "Predict period train12\n",
      "Predict period train6\n",
      "Predict period train9\n",
      "Predict period train7\n",
      "Predict period train14\n",
      "Predict period train2\n",
      "Predict period train11\n",
      "Predict period train1\n",
      "Predict period\n",
      "Predict period train13\n",
      "Predict period train10\n",
      "Predict period train3\n",
      "Predict period train4\n",
      "Predict period train9\n",
      "Predict period train8\n",
      "Predict period train7\n",
      "Predict period train2\n",
      "Predict period train6\n",
      "Predict period train11\n",
      "Predict period train12\n",
      "Predict period train5\n",
      "Predict period train14\n",
      "Predict period train1\n",
      "Predict period\n",
      "Predict period train13\n",
      "Predict period train10\n",
      "Predict period train3\n",
      "Predict period train4\n",
      "Predict period train9\n",
      "Predict period train8\n",
      "Predict period train7\n",
      "Predict period train2\n",
      "Predict period train6\n",
      "Predict period train11\n",
      "Predict period train12\n",
      "Predict period train5\n",
      "Predict period train14\n",
      "Predict period train1\n",
      "Train period train13 with 27969 data\n",
      "Train period train11 with 28059 data\n",
      "Train period train12 with 28065 data\n",
      "Train period train3 with 27979 data\n",
      "Train period train4 with 27791 data\n",
      "Train period train2 with 27877 data\n",
      "Train period train9 with 28154 data\n",
      "Train period train8 with 28076 data\n",
      "Train period train6 with 28006 data\n",
      "Train period train7 with 28033 data\n",
      "Train period train5 with 27866 data\n",
      "Train period train1 with 27945 data\n",
      "Train period train14 with 28249 data\n",
      "Train period train10 with 27931 data\n",
      "Predict period\n",
      "Predict period train6\n",
      "Predict period train1\n",
      "Predict period train2\n",
      "Predict period train12\n",
      "Predict period train10\n",
      "Predict period train8\n",
      "Predict period train9\n",
      "Predict period train14\n",
      "Predict period train5\n",
      "Predict period train7\n",
      "Predict period train3\n",
      "Predict period train4\n",
      "Predict period train13\n",
      "Predict period train11\n",
      "Predict period\n",
      "Predict period train6\n",
      "Predict period train1\n",
      "Predict period train2\n",
      "Predict period train12\n",
      "Predict period train10\n",
      "Predict period train8\n",
      "Predict period train9\n",
      "Predict period train14\n",
      "Predict period train5\n",
      "Predict period train7\n",
      "Predict period train3\n",
      "Predict period train4\n",
      "Predict period train13\n",
      "Predict period train11\n",
      "Predict period\n",
      "Predict period train13\n",
      "Predict period train11\n",
      "Predict period train12\n",
      "Predict period train3\n",
      "Predict period train4\n",
      "Predict period train2\n",
      "Predict period train9\n",
      "Predict period train8\n",
      "Predict period train6\n",
      "Predict period train7\n",
      "Predict period train5\n",
      "Predict period train1\n",
      "Predict period train14\n",
      "Predict period train10\n",
      "Predict period\n"
     ]
    }
   ],
   "source": [
    "scoring = {'acc': 'accuracy', 'log_loss': 'neg_log_loss'}\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=3)\n",
    "clf_xgb_14 = Xgb14Classifier(verbose=True)\n",
    "scores = cross_validate(estimator=clf_xgb_14, X=train_df, y=train_df['target'].values, cv=cv, scoring=scoring)\n",
    "\n",
    "print_val_score(scores, 'train_acc')\n",
    "print_val_score(scores, 'test_acc')\n",
    "print_val_score(scores, 'train_log_loss')\n",
    "print_val_score(scores, 'test_log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T09:59:25.567445Z",
     "start_time": "2017-11-23T09:59:25.562556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_xgb14_1000_all_param.pkl']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_xgb_14, 'clf_xgb14_1000_all_param.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Xgb period transformer to predict period and chain to pipeline\n",
    "(Not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T09:25:33.259709Z",
     "start_time": "2017-11-23T09:25:33.242853Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class XgbPeriodClassifier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, excluded_cols=[], verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.excluded_cols = excluded_cols\n",
    "        self.selected_cols = [\n",
    "            col for col in train_df.columns\n",
    "            if col not in (\n",
    "                self.excluded_cols + ['data_id', 'period', 'target'])\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, *_):\n",
    "        clf_xgb_period = XGBClassifier(\n",
    "            max_depth=7,\n",
    "            n_estimators=150,\n",
    "            reg_lambda=100,\n",
    "            objective='multi:softmax',\n",
    "            nthread=10)\n",
    "        X_train = X[self.selected_cols].values\n",
    "        y_train = X['period'].values\n",
    "        clf_xgb_period.fit(X_train, y_train)\n",
    "        self.clf_xgb_period = clf_xgb_period\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print y\n",
    "        try:\n",
    "            getattr(self, \"clf_xgb_period\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"Transformer hasn't been trained yet\")\n",
    "        # Don't predict period if it's training data\n",
    "        if 'period' in X.columns:\n",
    "            return X\n",
    "        X_train = X[self.selected_cols].values\n",
    "        X_period = self.clf_xgb_period.predict(X_train)\n",
    "        X_period_df = pd.DataFrame(X_period, columns=['period'])\n",
    "        return pd.concat([X, X_period_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T09:25:33.406210Z",
     "start_time": "2017-11-23T09:25:33.261282Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 91)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([df[x * 40000:x * 40000 + 100] for x in range(0, 14)])\n",
    "print train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T09:25:44.298306Z",
     "start_time": "2017-11-23T09:25:33.407755Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XgbPeriodClassifier(excluded_cols=[], verbose=True)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_period_transformer = XgbPeriodClassifier(verbose=True)\n",
    "xgb_period_transformer.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T09:25:44.319063Z",
     "start_time": "2017-11-23T09:25:44.299934Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 90)\n"
     ]
    }
   ],
   "source": [
    "val_df = pd.concat(\n",
    "    [df[x * 40000 + 1000:x * 40000 + 2000] for x in range(0, 14)]).drop(\n",
    "        'period', axis=1).reset_index(drop=True)\n",
    "print val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T08:50:16.436175Z",
     "start_time": "2017-11-23T08:50:15.644563Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 1)\n",
      "(14000, 90)\n",
      "(14000, 91)\n",
      "count      14000\n",
      "unique        14\n",
      "top       train8\n",
      "freq        1097\n",
      "Name: period, dtype: object\n"
     ]
    }
   ],
   "source": [
    "val_new_df = xgb_period_transformer.transform(val_df)\n",
    "print val_new_df.shape\n",
    "print val_new_df['period'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T12:00:35.673581Z",
     "start_time": "2017-11-23T12:00:35.670748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560000, 91)\n"
     ]
    }
   ],
   "source": [
    "train_df = df\n",
    "print train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T12:00:40.186225Z",
     "start_time": "2017-11-23T12:00:40.184060Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_xgb_14_final = Xgb14Classifier(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T12:02:56.092670Z",
     "start_time": "2017-11-23T12:00:47.783586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train period train1 with 40000 data\n",
      "Train period train2 with 40000 data\n",
      "Train period train3 with 40000 data\n",
      "Train period train4 with 40000 data\n",
      "Train period train5 with 40000 data\n",
      "Train period train6 with 40000 data\n",
      "Train period train7 with 40000 data\n",
      "Train period train8 with 40000 data\n",
      "Train period train9 with 40000 data\n",
      "Train period train10 with 40000 data\n",
      "Train period train11 with 40000 data\n",
      "Train period train12 with 40000 data\n",
      "Train period train13 with 40000 data\n",
      "Train period train14 with 40000 data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Xgb14Classifier(excluded_cols=[], verbose=True)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb_14_final.fit(train_df, train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T11:30:18.885403Z",
     "start_time": "2017-11-23T11:30:18.776407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_xgb14_40000_all_param.pkl']"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_xgb_14_final, 'clf_xgb14_40000_all_param.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T11:32:02.119326Z",
     "start_time": "2017-11-23T11:32:02.042374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf_xgb14_period_40000_all_param.pkl']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf_xgb_14_final.clf_xgb_period, 'clf_xgb14_period_40000_all_param.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T12:03:36.176105Z",
     "start_time": "2017-11-23T12:03:04.283241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict period\n",
      "Predict period train8\n",
      "Predict period train2\n",
      "Predict period train1\n",
      "Predict period train12\n",
      "Predict period train14\n",
      "Predict period train10\n",
      "Predict period train5\n",
      "Predict period train6\n",
      "Predict period train9\n",
      "Predict period train7\n",
      "Predict period train3\n",
      "Predict period train4\n",
      "Predict period train11\n",
      "Predict period train13\n",
      "(361500, 2)\n"
     ]
    }
   ],
   "source": [
    "pred = clf_xgb_14_final.predict_proba(df_test)\n",
    "print pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T12:12:46.611539Z",
     "start_time": "2017-11-23T12:12:46.573538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data_id  period        c1        c2        c3        c4   c5   c6  \\\n",
      "0        2  train1  0.655570 -0.000022 -0.000539 -0.001075  0.0  0.0   \n",
      "1        3  train1  1.646430 -0.000292 -0.008367  0.009497  0.0  0.0   \n",
      "2        5  train1 -0.743010  0.004642 -0.000647 -0.003290  0.0  0.0   \n",
      "3        7  train1  0.029770 -0.006343 -0.000635 -0.002516  0.0  0.0   \n",
      "4       10  train1 -0.660243  0.012591 -0.002098 -0.022264  0.0  0.0   \n",
      "5       13  train1  0.950848  0.011206  0.000272 -0.013013  0.0  0.0   \n",
      "6       17  train1 -1.160782 -0.008341  0.002040  0.003845  0.0  0.0   \n",
      "7       22  train1  1.160960 -0.000365  0.005032 -0.007527  0.0  0.0   \n",
      "8       25  train1 -0.719393  0.014472 -0.000373  0.025222  0.0  0.0   \n",
      "9       26  train1 -0.838567 -0.022329  0.002009 -0.000680  0.0  0.0   \n",
      "\n",
      "         c7   c8   ...         c80       c81       c82       c83  c84  c85  \\\n",
      "0  0.213390  0.0   ...   -0.023358 -0.017041  0.000000  0.060697  0.0  0.0   \n",
      "1  0.000000  0.0   ...   -0.059429 -0.009109  0.000000  0.021645  0.0  0.0   \n",
      "2  0.000000  0.0   ...    0.001796 -0.000104  0.000000 -0.024718  0.0  0.0   \n",
      "3  0.160313  0.0   ...   -0.005501  0.045308  0.000000 -0.148852  0.0  0.0   \n",
      "4  0.000000  0.0   ...    0.029034 -0.005847  0.000000 -0.007073  0.0  0.0   \n",
      "5  0.000000  0.0   ...    0.043054  0.005452  0.000000 -0.012588  0.0  0.0   \n",
      "6  0.000000  0.0   ...   -0.056733 -0.000314  0.000000 -0.020633  0.0  0.0   \n",
      "7  0.000000  0.0   ...    0.005563  0.002241  0.000000 -0.227928  0.0  0.0   \n",
      "8  0.000000  0.0   ...   -0.013038 -0.017801  0.213202  0.047527  0.0  0.0   \n",
      "9  0.000000  0.0   ...   -0.042771  0.000031  0.000000 -0.015817  0.0  0.0   \n",
      "\n",
      "        c86       c87       c88  target  \n",
      "0  0.000000 -0.000202 -0.140220       1  \n",
      "1  0.000000 -0.004382  0.455767       0  \n",
      "2  0.219566  0.072711  1.155580       0  \n",
      "3  0.000000 -0.101181 -0.954553       0  \n",
      "4  0.000000 -0.004842  0.436002       0  \n",
      "5  0.000000 -0.002362 -0.537312       1  \n",
      "6  0.000000 -0.042225 -0.610394       1  \n",
      "7  0.000000 -0.001267  1.637856       1  \n",
      "8  0.000000  0.065364 -0.757618       1  \n",
      "9  0.000000 -0.087656  2.415043       1  \n",
      "\n",
      "[10 rows x 91 columns]\n",
      "Predict period\n",
      "Predict period train1\n",
      "Predict period train7\n",
      "[[ 0.56249303  0.43750697]\n",
      " [ 0.69091058  0.30908939]\n",
      " [ 0.51784855  0.48215145]\n",
      " [ 0.38814425  0.61185575]\n",
      " [ 0.67394686  0.32605314]\n",
      " [ 0.40045202  0.59954798]\n",
      " [ 0.50728762  0.49271241]\n",
      " [ 0.54650259  0.45349741]\n",
      " [ 0.38778961  0.61221039]\n",
      " [ 0.28311163  0.71688837]]\n"
     ]
    }
   ],
   "source": [
    "df_test_sample = df[:10]\n",
    "print df_test_sample\n",
    "pred_sample = clf_xgb_14_final.predict_proba(df_test_sample)\n",
    "print pred_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T12:28:59.834131Z",
     "start_time": "2017-11-23T12:28:59.830825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(361500, 2)\n"
     ]
    }
   ],
   "source": [
    "print pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-23T12:29:04.670065Z",
     "start_time": "2017-11-23T12:29:04.266688Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pred[:,0]\n",
    "submission = pd.DataFrame({'data_id': df_test['data_id'],'target': predictions})\n",
    "submission.to_csv(\"submit_{:%Y%m%d-%H%M}.csv\".format(datetime.datetime.now()), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
